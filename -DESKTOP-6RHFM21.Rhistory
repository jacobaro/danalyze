scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) + scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, High vs. Low Rate")
cox.zph(m.surv)
# rerun our main model using 'timereg'
m.surv.timereg = timereg::timecox(formula = f, data = mela.pop, cluster = mela.pop$id)
# check proportional hazards
summary(m.surv.timereg) # this test says that 'sex' is fine but that rate is not, which matches what we find with our linear model
# get the plot data
plot.timereg = m.surv.timereg$cum %>% as_tibble %>% mutate(time = as.integer(time)) %>% group_by(time) %>% summarize(across(everything(), mean)) %>% filter(time != 0)
# lengthen
plot.timereg = plot.timereg %>% pivot_longer(-time)
# normalize
plot.timereg = plot.timereg %>% group_by(name) %>% mutate(value = scale(value))
# plot
ggplot(plot.timereg %>% filter(name != "(Intercept)"), aes(x = time, y = value)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_line(aes(color = name), size = 1) +
scale_color_manual("Variable Name", values = c("orangered", "steelblue4", "darkgreen")) +
scale_x_continuous(breaks = c(1, 5, 10)) +
theme_minimal() + labs(x = "Time", y = "Scaled Culumative Coefficient Value")
# the causalsens function doesnt like transforms in the formula so we just drop all those
f.cs = ~ sex + age + rate
# set outcome model
sens.out = lm(formula = update(f.cs, status_c0 ~ .), data = mela.pop)
# set treatment model
sens.treat = glm(formula = update(f, sex ~ . - sex), data = mela.pop, family = binomial)
# now run causalsens
sens.main = causalsens::causalsens(model.y = sens.out, model.t = sens.treat, cov.form = ~ age + rate, data = mela.pop, alpha = seq(-0.1, 0.1, by = 0.02))
# see what happened
sens.main$sens
plot(sens.main, type = "raw", bty = "n")
# plot(sens.main, type = "r.squared", bty = "n")
# run package version
m.surv.boot = analysis(runs = 1000, formula = f, data = mela.pop, cluster = ~ id)
needs::needs(danalyze, tidyverse)
# get the survival data -- data citation: https://www.rdocumentation.org/packages/timereg/versions/1.3-6/topics/mela.pop
data(mela.pop, package = "timereg")
# the data has fractional stop times, which wont work for our purposes so just use start + 1
mela.pop$stop2 = mela.pop$start + 1
# set sex to 1/0
mela.pop$sex = if_else(mela.pop$sex == 2, 1, 0)
# set the formula making sure to use our new stop time -- we include rate, which is the population offset; this does not make sense as an IV but helps to understand time-varying hazards
f = survival::Surv(start, stop2, status) ~ sex + log1p(age) + rate
# run survival model, clustering on 'id'
m.surv = survival::coxph(formula = f, data = mela.pop, cluster = id, x = T)
# show a summary of the results
summary(m.surv)
# run package version
m.surv.boot = analysis(runs = 1000, formula = f, data = mela.pop, cluster = ~ id)
# first show the results of the Cox model using the standard summary function
summary(m.surv)
# we can also use the 'danalyze' function which will produce the same results
# get_prediction_frequentist(m.surv)$coefficients
# then show the results of the bootstrapped model
results(m.surv.boot)$coefficients
# a helper function to identify if an event has occurred within X time forward from the current observation
# t = 0 means the current observation, t = 1 means within one time unit forward of the current observation
within_time = function(x, t, outcome = 1) {
maxl = length(x)
sapply(1:maxl, function(z) {
maxt = min(maxl, z + t)
# get the outcome -- the ordering here matters -- first we check if it happened (return '1'), then we check to see if we know it did not happen (return 'NA' if we are not sure or '0' otherwise)
if(any(na.omit(x[z:maxt]) == outcome)) return(outcome) # we know it happened
if(z + t > maxt || any(is.na(x[1:maxt]))) return(NA) # these are outcomes we do not know -- they have not happened yet but could in a time so we set them to 'NA'
return(0) # we know it did not happen
})
}
# we will create 10 dependent variables that record the occurrence of the outcome within X time ('status_c0' is identical to 'status')
mela.pop = mela.pop %>% arrange(id, start, stop2) %>% group_by(id) %>%
mutate(across(status, .fns = list(c0 = ~ within_time(.x, 0), c1 = ~ within_time(.x, 1), c2 = ~ within_time(.x, 2), c3 = ~ within_time(.x, 3), c4 = ~ within_time(.x, 4),
c5 = ~ within_time(.x, 5), c6 = ~ within_time(.x, 6), c7 = ~ within_time(.x, 7), c8 = ~ within_time(.x, 8), c9= ~ within_time(.x, 9))))
# prediction for danalyze -- very easy to see what is happening!
pr.boot = pr(sex = c(1, 0))
# prediction for built-in survival predict function -- set through 10 subsequent time units
pr.survival = bind_rows(tibble(sex = 1, age = mean(mela.pop$age), rate = mean(mela.pop$rate), start = 0, stop2 = 1:10, status = 0),
tibble(sex = 0, age = mean(mela.pop$age), rate = mean(mela.pop$rate), start = 0, stop2 = 1:10, status = 0))
# run a linear model (on binomial data)
m.surv.linear = lapply(0:9, function(i) {
# set the formula
f.t = update(f, as.formula(paste0("status_c", i, " ~ .")))
# run the model -- binomial outcome but we are running it using a gaussian family -- could also just use lm but this makes it easier to check what happens when you swap family
out.t = glm(formula = f.t, data = mela.pop, family = gaussian)
# get prediction using the prediction we created above -- the SE is pretty large when using just id, but that is likely the more accurate assessment
# this uses a 'danalyze' function
r.t = get_prediction_frequentist(out.t, cluster = ~ id, predictions = pr.boot)
# save
r.t
})
# get contrasts from the set of linear models
out.linear = map_dfr(m.surv.linear, "contrasts", .id = ".time")
out.linear$.time = as.numeric(out.linear$.time)
# get the results from the bootstrapped survival model
out.boot = results(object = m.surv.boot, predictions = pr.boot, times = 1:10)$contrasts
# for sake of comparison we can also plot the predictions (but not easily the contrasts) for the standard survival model
# get contrasts from the survival model
out.surv = predict(m.surv, newdata = pr.survival, type = "survival", se.fit = T)
# turn it into cumulative incidence (the CIF common in interpreting competing risks models)
out.surv = tibble(
.time = c(1:10, 1:10),
c = 1 - out.surv$fit,
c.low = c - qnorm(0.975) * out.surv$se.fit,
c.high = c + qnorm(0.975) * out.surv$se.fit
)
# now combine the contrasts from the set of linear models and the bootstrapped survival model
# set name for easy comparison
out.linear$.type = "Linear Series"
out.boot$.type = "Survival"
out.all = bind_rows(out.linear %>% select(.type, .time, c:c.high), out.boot %>% select(.type, .time, c:c.high))
# plot -- assuming that '2' means male and '1' means female
ggplot(out.all, aes(x = .time, y = c, ymin = c.low, ymax = c.high)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_ribbon(aes(fill = .type), alpha = 0.4) + geom_line(aes(color = .type), size = 1) +
scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) + scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, Male vs. Female")
# new prediction -- we use 'rate' but the same issue will occur for 'age' as the hazards vary with time (see below for this assessment) -- all that needs to be done is to change 'rate' to 'age'
pr.boot = pr(rate = create_values(mela.pop$rate)) # -- the 'age' prediction: pr(age = create_values(mela.pop$age))
# run a linear model (on binomial data)
m.surv.linear = lapply(0:9, function(i) {
# set the formula
f.t = update(f, as.formula(paste0("status_c", i, " ~ .")))
# run the model -- binomial outcome but we are running it using a gaussian family -- could also just use lm but this makes it easier to check what happens when you swap family
out.t = glm(formula = f.t, data = mela.pop, family = gaussian)
# this outcome model (run as an lm instead of a glm) can also be saved and used for blackwell's sensivitiy analysis
# get prediction using the prediction we created above -- the SE is pretty large when using just id, but that is likely the more accurate assessment
# this uses a 'danalyze' function
r.t = get_prediction_frequentist(out.t, cluster = ~ id, predictions = pr.boot)
# save
r.t
})
# get contrasts from the set of linear models
out.linear = map_dfr(m.surv.linear, "contrasts", .id = ".time")
out.linear$.time = as.numeric(out.linear$.time)
# get the results from the bootstrapped survival model
out.boot = results(object = m.surv.boot, predictions = pr.boot, times = 1:10)$contrasts
# set name for easy comparison
out.linear$.type = "Linear Series"
out.boot$.type = "Survival"
out.all = bind_rows(out.linear %>% select(.type, .time, c:c.high), out.boot %>% select(.type, .time, c:c.high))
# plot again
ggplot(out.all, aes(x = .time, y = c, ymin = c.low, ymax = c.high)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_ribbon(aes(fill = .type), alpha = 0.4) + geom_line(aes(color = .type), size = 1) +
scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) + scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, High vs. Low Rate")
cox.zph(m.surv)
# rerun our main model using 'timereg'
m.surv.timereg = timereg::timecox(formula = f, data = mela.pop, cluster = mela.pop$id)
# check proportional hazards
summary(m.surv.timereg) # this test says that 'sex' is fine but that rate is not, which matches what we find with our linear model
# get the plot data
plot.timereg = m.surv.timereg$cum %>% as_tibble %>% mutate(time = as.integer(time)) %>% group_by(time) %>% summarize(across(everything(), mean)) %>% filter(time != 0)
# lengthen
plot.timereg = plot.timereg %>% pivot_longer(-time)
# normalize
plot.timereg = plot.timereg %>% group_by(name) %>% mutate(value = scale(value))
# plot
ggplot(plot.timereg %>% filter(name != "(Intercept)"), aes(x = time, y = value)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_line(aes(color = name), size = 1) +
scale_color_manual("Variable Name", values = c("orangered", "steelblue4", "darkgreen")) +
scale_x_continuous(breaks = c(1, 5, 10)) +
theme_minimal() + labs(x = "Time", y = "Scaled Culumative Coefficient Value")
# the causalsens function doesnt like transforms in the formula so we just drop all those
f.cs = ~ sex + age + rate
# set outcome model
sens.out = lm(formula = update(f.cs, status_c0 ~ .), data = mela.pop)
# set treatment model
sens.treat = glm(formula = update(f, sex ~ . - sex), data = mela.pop, family = binomial)
# now run causalsens
sens.main = causalsens::causalsens(model.y = sens.out, model.t = sens.treat, cov.form = ~ age + rate, data = mela.pop, alpha = seq(-0.1, 0.1, by = 0.02))
# see what happened
sens.main$sens
# plot the raw sensitvity resutls based on alpha
plot(sens.main, type = "raw", bty = "n")
# we could also plot based on rsquared
# plot(sens.main, type = "r.squared", bty = "n")
needs::needs(danalyze, tidyverse)
# get the survival data -- data citation: https://www.rdocumentation.org/packages/timereg/versions/1.3-6/topics/mela.pop
data(mela.pop, package = "timereg")
# the data has fractional stop times, which wont work for our purposes so just use start + 1
mela.pop$stop2 = mela.pop$start + 1
# set sex to 1/0
mela.pop$sex = if_else(mela.pop$sex == 2, 1, 0)
# set the formula making sure to use our new stop time -- we include rate, which is the population offset; this does not make sense as an IV but helps to understand time-varying hazards
f = survival::Surv(start, stop2, status) ~ sex + log1p(age) + rate
# run survival model, clustering on 'id'
m.surv = survival::coxph(formula = f, data = mela.pop, cluster = id, x = T)
# show a summary of the results
summary(m.surv)
# run package version
m.surv.boot = analysis(runs = 1000, formula = f, data = mela.pop, cluster = ~ id)
# first show the results of the Cox model using the standard summary function
summary(m.surv)
# we can also use the 'danalyze' function which will produce the same results
# get_prediction_frequentist(m.surv)$coefficients
# then show the results of the bootstrapped model
results(m.surv.boot)$coefficients
# a helper function to identify if an event has occurred within X time forward from the current observation
# t = 0 means the current observation, t = 1 means within one time unit forward of the current observation
within_time = function(x, t, outcome = 1) {
maxl = length(x)
sapply(1:maxl, function(z) {
maxt = min(maxl, z + t)
# get the outcome -- the ordering here matters -- first we check if it happened (return '1'), then we check to see if we know it did not happen (return 'NA' if we are not sure or '0' otherwise)
if(any(na.omit(x[z:maxt]) == outcome)) return(outcome) # we know it happened
if(z + t > maxt || any(is.na(x[1:maxt]))) return(NA) # these are outcomes we do not know -- they have not happened yet but could in a time so we set them to 'NA'
return(0) # we know it did not happen
})
}
# we will create 10 dependent variables that record the occurrence of the outcome within X time ('status_c0' is identical to 'status')
mela.pop = mela.pop %>% arrange(id, start, stop2) %>% group_by(id) %>%
mutate(across(status, .fns = list(c0 = ~ within_time(.x, 0), c1 = ~ within_time(.x, 1), c2 = ~ within_time(.x, 2),
c3 = ~ within_time(.x, 3), c4 = ~ within_time(.x, 4),
c5 = ~ within_time(.x, 5), c6 = ~ within_time(.x, 6), c7 = ~ within_time(.x, 7),
c8 = ~ within_time(.x, 8), c9= ~ within_time(.x, 9))))
# prediction for danalyze -- very easy to see what is happening!
pr.boot = pr(sex = c(1, 0))
# prediction for built-in survival predict function -- set through 10 subsequent time units
pr.survival = bind_rows(
tibble(sex = 1, age = mean(mela.pop$age), rate = mean(mela.pop$rate), start = 0, stop2 = 1:10, status = 0),
tibble(sex = 0, age = mean(mela.pop$age), rate = mean(mela.pop$rate), start = 0, stop2 = 1:10, status = 0))
# run a linear model (on binomial data)
m.surv.linear = lapply(0:9, function(i) {
# set the formula
f.t = update(f, as.formula(paste0("status_c", i, " ~ .")))
# run the model -- binomial outcome but we are running it using a gaussian family -- could also just use lm but this makes it easier to check what happens when you swap family
out.t = glm(formula = f.t, data = mela.pop, family = gaussian)
# get prediction using the prediction we created above -- the SE is pretty large when using just id, but that is likely the more accurate assessment
# this uses a 'danalyze' function
r.t = get_prediction_frequentist(out.t, cluster = ~ id, predictions = pr.boot)
# save
r.t
})
# get contrasts from the set of linear models
out.linear = map_dfr(m.surv.linear, "contrasts", .id = ".time")
out.linear$.time = as.numeric(out.linear$.time)
# get the results from the bootstrapped survival model
out.boot = results(object = m.surv.boot, predictions = pr.boot, times = 1:10)$contrasts
# for sake of comparison we can also plot the predictions (but not easily the contrasts) for the standard survival model
# get contrasts from the survival model
out.surv = predict(m.surv, newdata = pr.survival, type = "survival", se.fit = T)
# turn it into cumulative incidence (the CIF common in interpreting competing risks models)
out.surv = tibble(
.time = c(1:10, 1:10),
c = 1 - out.surv$fit,
c.low = c - qnorm(0.975) * out.surv$se.fit,
c.high = c + qnorm(0.975) * out.surv$se.fit
)
# now combine the contrasts from the set of linear models and the bootstrapped survival model
# set name for easy comparison
out.linear$.type = "Linear Series"
out.boot$.type = "Survival"
out.all = bind_rows(out.linear %>% select(.type, .time, c:c.high), out.boot %>% select(.type, .time, c:c.high))
# plot -- assuming that '2' means male and '1' means female
ggplot(out.all, aes(x = .time, y = c, ymin = c.low, ymax = c.high)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_ribbon(aes(fill = .type), alpha = 0.4) + geom_line(aes(color = .type), size = 1) +
scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, Male vs. Female")
# new prediction -- we use 'rate' but the same issue will occur for 'age' as the hazards vary with time (see below for this assessment) -- all that needs to be done is to change 'rate' to 'age'
pr.boot = pr(rate = create_values(mela.pop$rate)) # -- the 'age' prediction: pr(age = create_values(mela.pop$age))
# run a linear model (on binomial data)
m.surv.linear = lapply(0:9, function(i) {
# set the formula
f.t = update(f, as.formula(paste0("status_c", i, " ~ .")))
# run the model -- binomial outcome but we are running it using a gaussian family -- could also just use lm but this makes it easier to check what happens when you swap family
out.t = glm(formula = f.t, data = mela.pop, family = gaussian)
# this outcome model (run as an lm instead of a glm) can also be saved and used for blackwell's sensivitiy analysis
# get prediction using the prediction we created above -- the SE is pretty large when using just id, but that is likely the more accurate assessment
# this uses a 'danalyze' function
r.t = get_prediction_frequentist(out.t, cluster = ~ id, predictions = pr.boot)
# save
r.t
})
# get contrasts from the set of linear models
out.linear = map_dfr(m.surv.linear, "contrasts", .id = ".time")
out.linear$.time = as.numeric(out.linear$.time)
# get the results from the bootstrapped survival model
out.boot = results(object = m.surv.boot, predictions = pr.boot, times = 1:10)$contrasts
# set name for easy comparison
out.linear$.type = "Linear Series"
out.boot$.type = "Survival"
out.all = bind_rows(out.linear %>% select(.type, .time, c:c.high), out.boot %>% select(.type, .time, c:c.high))
# plot again
ggplot(out.all, aes(x = .time, y = c, ymin = c.low, ymax = c.high)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_ribbon(aes(fill = .type), alpha = 0.4) + geom_line(aes(color = .type), size = 1) +
scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, High vs. Low Rate")
cox.zph(m.surv)
# rerun our main model using 'timereg'
m.surv.timereg = timereg::timecox(formula = f, data = mela.pop, cluster = mela.pop$id)
# check proportional hazards
summary(m.surv.timereg) # this test says that 'sex' is fine but that rate is not, which matches what we find with our linear model
# get the plot data
plot.timereg = m.surv.timereg$cum %>% as_tibble %>% mutate(time = as.integer(time)) %>% group_by(time) %>% summarize(across(everything(), mean)) %>% filter(time != 0)
# lengthen
plot.timereg = plot.timereg %>% pivot_longer(-time)
# normalize
plot.timereg = plot.timereg %>% group_by(name) %>% mutate(value = scale(value))
# plot
ggplot(plot.timereg %>% filter(name != "(Intercept)"), aes(x = time, y = value)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_line(aes(color = name), size = 1) +
scale_color_manual("Variable Name", values = c("orangered", "steelblue4", "darkgreen")) +
scale_x_continuous(breaks = c(1, 5, 10)) +
theme_minimal() + labs(x = "Time", y = "Scaled Culumative Coefficient Value")
# the causalsens function doesnt like transforms in the formula so we just drop all those
f.cs = ~ sex + age + rate
# set outcome model
sens.out = lm(formula = update(f.cs, status_c0 ~ .), data = mela.pop)
# set treatment model
sens.treat = glm(formula = update(f, sex ~ . - sex), data = mela.pop, family = binomial)
# now run causalsens
sens.main = causalsens::causalsens(model.y = sens.out, model.t = sens.treat, cov.form = ~ age + rate,
data = mela.pop, alpha = seq(-0.1, 0.1, by = 0.02))
# see what happened
sens.main$sens
# plot the raw sensitvity resutls based on alpha
plot(sens.main, type = "raw", bty = "n")
# we could also plot based on rsquared
# plot(sens.main, type = "r.squared", bty = "n")
needs::needs(danalyze, tidyverse)
# get the survival data from an existing package
# data citation: https://www.rdocumentation.org/packages/timereg/versions/1.3-6/topics/mela.pop
data(mela.pop, package = "timereg")
# the data has fractional stop times, which wont work for our purposes so just use start + 1
mela.pop$stop2 = mela.pop$start + 1
# set sex to 1/0
mela.pop$sex = if_else(mela.pop$sex == 2, 1, 0)
# set the formula making sure to use our new stop time -- we include rate, which is the population offset; this does not make sense as an IV but helps to understand time-varying hazards
f = survival::Surv(start, stop2, status) ~ sex + log1p(age) + rate
# run survival model, clustering on 'id'
m.surv = survival::coxph(formula = f, data = mela.pop, cluster = id, x = T)
# show a summary of the results
summary(m.surv)
# run package version
m.surv.boot = analysis(runs = 1000, formula = f, data = mela.pop, cluster = ~ id)
# first show the results of the Cox model using the standard summary function
summary(m.surv)
# we can also use the 'danalyze' function which will produce the same results
# get_prediction_frequentist(m.surv)$coefficients
# then show the results of the bootstrapped model
results(m.surv.boot)$coefficients
# a helper function to identify if an event has occurred within X time forward from the current observation
# t = 0 means the current observation, t = 1 means within one time unit forward of the current observation
within_time = function(x, t, outcome = 1) {
maxl = length(x)
sapply(1:maxl, function(z) {
maxt = min(maxl, z + t)
# get the outcome -- the ordering here matters -- first we check if it happened (return '1')
# then we check to see if we know it did not happen (return 'NA' if we are not sure or '0' otherwise)
if(any(na.omit(x[z:maxt]) == outcome)) return(outcome) # we know it happened
if(z + t > maxt || any(is.na(x[1:maxt]))) return(NA) # these are outcomes we do not know so we set them to 'NA'
return(0) # we know it did not happen
})
}
# we will create 10 dependent variables that record the occurrence of the outcome within X time ('status_c0' is identical to 'status')
mela.pop = mela.pop %>% arrange(id, start, stop2) %>% group_by(id) %>%
mutate(across(status, .fns = list(c0 = ~ within_time(.x, 0), c1 = ~ within_time(.x, 1), c2 = ~ within_time(.x, 2),
c3 = ~ within_time(.x, 3), c4 = ~ within_time(.x, 4),
c5 = ~ within_time(.x, 5), c6 = ~ within_time(.x, 6), c7 = ~ within_time(.x, 7),
c8 = ~ within_time(.x, 8), c9= ~ within_time(.x, 9))))
# prediction for danalyze -- very easy to see what is happening!
pr.boot = pr(sex = c(1, 0))
# prediction for built-in survival predict function -- set through 10 subsequent time units
pr.survival = bind_rows(
tibble(sex = 1, age = mean(mela.pop$age), rate = mean(mela.pop$rate), start = 0, stop2 = 1:10, status = 0),
tibble(sex = 0, age = mean(mela.pop$age), rate = mean(mela.pop$rate), start = 0, stop2 = 1:10, status = 0))
# run a linear model (on binomial data)
m.surv.linear = lapply(0:9, function(i) {
# set the formula
f.t = update(f, as.formula(paste0("status_c", i, " ~ .")))
# run the model -- binomial outcome but we are running it using a gaussian family -- could also just use lm but this makes it easier to check what happens when you swap family
out.t = glm(formula = f.t, data = mela.pop, family = gaussian)
# get prediction using the prediction we created above -- the SE is pretty large when using just id, but that is likely the more accurate assessment
# this uses a 'danalyze' function
r.t = get_prediction_frequentist(out.t, cluster = ~ id, predictions = pr.boot)
# save
r.t
})
# get contrasts from the set of linear models
out.linear = map_dfr(m.surv.linear, "contrasts", .id = ".time")
out.linear$.time = as.numeric(out.linear$.time)
# get the results from the bootstrapped survival model
out.boot = results(object = m.surv.boot, predictions = pr.boot, times = 1:10)$contrasts
# for sake of comparison we can also plot the predictions (but not easily the contrasts) for the standard survival model
# get contrasts from the survival model
out.surv = predict(m.surv, newdata = pr.survival, type = "survival", se.fit = T)
# turn it into cumulative incidence (the CIF common in interpreting competing risks models)
out.surv = tibble(
.time = c(1:10, 1:10),
c = 1 - out.surv$fit,
c.low = c - qnorm(0.975) * out.surv$se.fit,
c.high = c + qnorm(0.975) * out.surv$se.fit
)
# now combine the contrasts from the set of linear models and the bootstrapped survival model
# set name for easy comparison
out.linear$.type = "Linear Series"
out.boot$.type = "Survival"
out.all = bind_rows(out.linear %>% select(.type, .time, c:c.high), out.boot %>% select(.type, .time, c:c.high))
# plot -- assuming that '2' means male and '1' means female
ggplot(out.all, aes(x = .time, y = c, ymin = c.low, ymax = c.high)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_ribbon(aes(fill = .type), alpha = 0.4) + geom_line(aes(color = .type), size = 1) +
scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, Male vs. Female")
# new prediction
# we use 'rate' but the same issue will occur for 'age' as the hazards vary with time (see below for this assessment)
# ll that needs to be done is to change 'rate' to 'age'
pr.boot = pr(rate = create_values(mela.pop$rate)) # -- the 'age' prediction: pr(age = create_values(mela.pop$age))
# run a linear model (on binomial data)
m.surv.linear = lapply(0:9, function(i) {
# set the formula
f.t = update(f, as.formula(paste0("status_c", i, " ~ .")))
# run the model -- binomial outcome but we are running it using a gaussian family
# could also just use lm but this makes it easier to check what happens when you swap family
out.t = glm(formula = f.t, data = mela.pop, family = gaussian)
# this outcome model (run as an lm instead of a glm) can also be saved and used for blackwell's sensivitiy analysis
# get prediction using the prediction we created above
# the SE is pretty large when using just id, but that is likely the more accurate assessment
# this uses a 'danalyze' function
r.t = get_prediction_frequentist(out.t, cluster = ~ id, predictions = pr.boot)
# save
r.t
})
# get contrasts from the set of linear models
out.linear = map_dfr(m.surv.linear, "contrasts", .id = ".time")
out.linear$.time = as.numeric(out.linear$.time)
# get the results from the bootstrapped survival model
out.boot = results(object = m.surv.boot, predictions = pr.boot, times = 1:10)$contrasts
# set name for easy comparison
out.linear$.type = "Linear Series"
out.boot$.type = "Survival"
out.all = bind_rows(out.linear %>% select(.type, .time, c:c.high), out.boot %>% select(.type, .time, c:c.high))
# plot again
ggplot(out.all, aes(x = .time, y = c, ymin = c.low, ymax = c.high)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_ribbon(aes(fill = .type), alpha = 0.4) + geom_line(aes(color = .type), size = 1) +
scale_fill_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_color_manual("Model Type", values = c("orangered", "steelblue4")) +
scale_x_continuous(breaks = c(1, 5, 10)) + scale_y_continuous(labels = scales::percent_format()) +
theme_minimal() + labs(x = "Time", y = "Change in Cumulative Incidence, High vs. Low Rate")
cox.zph(m.surv)
# rerun our main model using 'timereg'
m.surv.timereg = timereg::timecox(formula = f, data = mela.pop, cluster = mela.pop$id)
# check proportional hazards
# this test says that 'sex' is fine but that rate is not, which matches what we find with our linear model
summary(m.surv.timereg)
# get the plot data
plot.timereg = m.surv.timereg$cum %>% as_tibble %>% mutate(time = as.integer(time)) %>% group_by(time) %>%
summarize(across(everything(), mean)) %>% filter(time != 0)
# lengthen
plot.timereg = plot.timereg %>% pivot_longer(-time)
# normalize
plot.timereg = plot.timereg %>% group_by(name) %>% mutate(value = scale(value))
# plot
ggplot(plot.timereg %>% filter(name != "(Intercept)"), aes(x = time, y = value)) +
geom_hline(yintercept = 0, linetype = "dashed", color = "grey80", size = 1.5) +
geom_line(aes(color = name), size = 1) +
scale_color_manual("Variable Name", values = c("orangered", "steelblue4", "darkgreen")) +
scale_x_continuous(breaks = c(1, 5, 10)) +
theme_minimal() + labs(x = "Time", y = "Scaled Culumative Coefficient Value")
# the causalsens function doesnt like transforms in the formula so we just drop all those
f.cs = ~ sex + age + rate
# set outcome model
sens.out = lm(formula = update(f.cs, status_c0 ~ .), data = mela.pop)
# set treatment model
sens.treat = glm(formula = update(f, sex ~ . - sex), data = mela.pop, family = binomial)
# now run causalsens
sens.main = causalsens::causalsens(model.y = sens.out, model.t = sens.treat, cov.form = ~ age + rate,
data = mela.pop, alpha = seq(-0.1, 0.1, by = 0.02))
# see what happened
sens.main$sens
# plot the raw sensitvity resutls based on alpha
plot(sens.main, type = "raw", bty = "n")
# we could also plot based on rsquared
# plot(sens.main, type = "r.squared", bty = "n")
unlink("R/examples/cumulative_linear_cache", recursive = TRUE)
unlink("R/examples/cumulative_linear_cache", recursive = TRUE)
unlink("R/examples/cumulative_linear_cache", recursive = TRUE)
devtools::document()
library(danalyze)
library(danalyze)
devtools::document()
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
library(danalyze)
